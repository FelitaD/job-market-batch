{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Streamlined ingestion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "\n",
    "from config.definitions import JOB_MARKET_DB_USER, JOB_MARKET_DB_PWD\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Name Entity Recognition of technologies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Manual annotation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "english_collective_dict = {'TRAINING_DATA': []}\n",
    "french_collective_dict = {'TRAINING_DATA': []}\n",
    "\n",
    "def structure_training_data(text, kw_list, collective_dict):\n",
    "    results = []\n",
    "    entities = []\n",
    "\n",
    "    for kw in tqdm(kw_list):\n",
    "        search_ = re.finditer(kw, text, flags=re.IGNORECASE)\n",
    "\n",
    "        matches_positions = [[m.start(), m.end()] for m in search_]\n",
    "\n",
    "        if len(matches_positions) > 0:\n",
    "            for match_positions in matches_positions:\n",
    "                start = match_positions[0]\n",
    "                end = match_positions[1]\n",
    "                entities.append((start, end, \"TECHNO\"))\n",
    "        else:\n",
    "            print(\"No pattern matches found. Keyword: \", kw)\n",
    "\n",
    "    if len(entities) > 0:\n",
    "        results = [text, {'entities': entities}]\n",
    "        collective_dict['TRAINING_DATA'].append(results)\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting training examples into spaCy Doc objects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def create_training(train_data):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(train_data):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "\n",
    "        for start, end, label in annot['entities']:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode='contract')\n",
    "\n",
    "            if span is None:\n",
    "                print('Skipping entity.')\n",
    "            else:\n",
    "                ents.append(span)\n",
    "                try:\n",
    "                    doc.ents = ents\n",
    "                except:\n",
    "                    ents.pop()\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return db"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. English"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "16.0"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_collective_dict['TRAINING_DATA']) / 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 84.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity.\n",
      "Skipping entity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 119.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n",
      "Skipping entity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "english_nlp = spacy.blank('en')\n",
    "\n",
    "english_train_data = english_collective_dict['TRAINING_DATA'][:19]\n",
    "english_evaluation_data = english_collective_dict['TRAINING_DATA'][19:]\n",
    "\n",
    "TRAIN_DATA_DOC = create_training(english_train_data)\n",
    "TRAIN_DATA_DOC.to_disk('./train_data/ENGLISH_TRAIN_DATA.spacy')\n",
    "\n",
    "VALID_DATA_DOC = create_training(english_evaluation_data)\n",
    "VALID_DATA_DOC.to_disk('./train_data/ENGLISH_VALID_DATA.spacy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. English"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python3 -m spacy init fill-config base_config_english.cfg english_config.cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2mâœ” Auto-filled config with all values\u001B[0m\r\n",
      "\u001B[38;5;2mâœ” Saved config\u001B[0m\r\n",
      "english_config.cfg\r\n",
      "You can now add your data and train your pipeline:\r\n",
      "python -m spacy train english_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mâ„¹ Saving to output directory: output_english\u001B[0m\r\n",
      "\u001B[38;5;4mâ„¹ Using CPU\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "=========================== Initializing pipeline ===========================\u001B[0m\r\n",
      "[2022-03-25 11:30:17,359] [INFO] Set up nlp object from config\r\n",
      "[2022-03-25 11:30:17,367] [INFO] Pipeline: ['tok2vec', 'ner']\r\n",
      "[2022-03-25 11:30:17,370] [INFO] Created vocabulary\r\n",
      "[2022-03-25 11:30:17,371] [INFO] Finished initializing nlp object\r\n",
      "[2022-03-25 11:30:18,673] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\r\n",
      "\u001B[38;5;2mâœ” Initialized pipeline\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "============================= Training pipeline =============================\u001B[0m\r\n",
      "\u001B[38;5;4mâ„¹ Pipeline: ['tok2vec', 'ner']\u001B[0m\r\n",
      "\u001B[38;5;4mâ„¹ Initial learn rate: 0.001\u001B[0m\r\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \r\n",
      "---  ------  ------------  --------  ------  ------  ------  ------\r\n",
      "  0       0          0.00    213.33    0.00    0.00    0.00    0.00\r\n",
      " 10     200         53.47   4900.04   34.62   25.00   56.25    0.35\r\n",
      " 21     400       3513.29    310.13   38.64   30.36   53.12    0.39\r\n",
      " 31     600        623.45     92.58   33.33   28.26   40.62    0.33\r\n",
      " 42     800         20.03     52.11   35.00   29.17   43.75    0.35\r\n",
      " 52    1000         11.55     47.89   32.43   28.57   37.50    0.32\r\n",
      " 63    1200         22.76     49.01   42.35   33.96   56.25    0.42\r\n",
      " 73    1400         48.25     56.20   44.94   35.09   62.50    0.45\r\n",
      " 84    1600         40.50     52.76   40.45   31.58   56.25    0.40\r\n",
      " 94    1800         20.85     40.93   39.62   28.38   65.62    0.40\r\n",
      "105    2000         13.41     39.84   44.94   35.09   62.50    0.45\r\n",
      "115    2200          4.06     31.16   40.00   31.03   56.25    0.40\r\n",
      "126    2400          6.85     37.31   37.78   29.31   53.12    0.38\r\n",
      "136    2600          7.42     39.24   39.18   29.23   59.38    0.39\r\n",
      "147    2800         25.74     45.30   35.71   28.85   46.88    0.36\r\n",
      "157    3000         40.12     48.28   36.00   26.47   56.25    0.36\r\n",
      "\u001B[38;5;2mâœ” Saved pipeline to output directory\u001B[0m\r\n",
      "output_english/model-last\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train english_config.cfg --output ./output_english"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. French"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!python3 -m spacy init fill-config base_config_french.cfg french_config.cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!python3 -m spacy train french_config.cfg --output ./output_french"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model '/Users/donor/PycharmProjects/DE_job_market/nlp/output_english/model-best'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Input \u001B[0;32mIn [27]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m nlp_english_output \u001B[38;5;241m=\u001B[39m \u001B[43mspacy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/donor/PycharmProjects/DE_job_market/nlp/output_english/model-best\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m doc \u001B[38;5;241m=\u001B[39m nlp_english_output(english_jobs\u001B[38;5;241m.\u001B[39mtext[\u001B[38;5;241m716\u001B[39m])\n\u001B[1;32m      4\u001B[0m colors \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTECHNO\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear-gradient(90deg, #E1D436, #F59710)\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
      "File \u001B[0;32m~/PycharmProjects/Reviews/venv/lib/python3.9/site-packages/spacy/__init__.py:51\u001B[0m, in \u001B[0;36mload\u001B[0;34m(name, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\n\u001B[1;32m     31\u001B[0m     name: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     config: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Config] \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mSimpleFrozenDict(),\n\u001B[1;32m     37\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Language:\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    name (str): Package name or model path.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Reviews/venv/lib/python3.9/site-packages/spacy/util.py:427\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(name, vocab, disable, exclude, config)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m OLD_MODEL_SHORTCUTS:\n\u001B[1;32m    426\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE941\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname, full\u001B[38;5;241m=\u001B[39mOLD_MODEL_SHORTCUTS[name]))  \u001B[38;5;66;03m# type: ignore[index]\u001B[39;00m\n\u001B[0;32m--> 427\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE050\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname))\n",
      "\u001B[0;31mOSError\u001B[0m: [E050] Can't find model '/Users/donor/PycharmProjects/DE_job_market/nlp/output_english/model-best'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp_english_output = spacy.load('/Users/donor/PycharmProjects/DE_job_market/nlp/output_english/model-best')\n",
    "\n",
    "doc = nlp_english_output(english_jobs.text[716])\n",
    "colors = {\"TECHNO\": \"linear-gradient(90deg, #E1D436, #F59710)\"}\n",
    "options = {\"ents\": [\"TECHNO\"], \"colors\": colors}\n",
    "displacy.render(doc, style='ent', options=options)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting technologies into a new column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [],
   "source": [
    "nlp_english_output = spacy.load('/Users/donor/PycharmProjects/DE_job_market/nlp/output_english/model-best')\n",
    "nlp.max_length = 3000000\n",
    "\n",
    "def extract_technos(text):\n",
    "    doc = nlp_english_output(text)\n",
    "    technos = [ent.text for ent in doc.ents]\n",
    "    return list(set(technos))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/2w2qlxsn13s9qyf11rtgzkkr0000gn/T/ipykernel_45579/3063333733.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  english_jobs['technos'] = english_jobs['text'].apply(lambda x: extract_technos(x))\n"
     ]
    }
   ],
   "source": [
    "english_jobs['technos'] = english_jobs['text'].apply(lambda x: extract_technos(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    url  \\\n0     https://datai.jobs/job/lyft-data-engineer-kyiv...   \n1     https://datai.jobs/job/chargepoint-data-engine...   \n2     https://datai.jobs/job/spotify-data-engineer-e...   \n3     https://datai.jobs/job/spotify-staff-data-engi...   \n4     https://datai.jobs/job/spotify-data-engineer-s...   \n...                                                 ...   \n1050  https://www.welcometothejungle.com/fr/companie...   \n1057  https://www.welcometothejungle.com/fr/companie...   \n1064  https://www.welcometothejungle.com/fr/companie...   \n1065  https://www.welcometothejungle.com/fr/companie...   \n1069  https://www.welcometothejungle.com/fr/companie...   \n\n                                 title               company       location  \\\n0                 Data Engineer â€“ Kyiv                  Lyft  Kyiv, Ukraine   \n1                        Data Engineer           ChargePoint      Amsterdam   \n2           Data Engineer â€“ Experience               Spotify      Stockholm   \n3     Staff Data Engineer â€“ Experience               Spotify      Stockholm   \n4                        Data Engineer               Spotify      Stockholm   \n...                                ...                   ...            ...   \n1050                     Data Engineer  GLOBAL SAVINGS GROUP        MÃ¼nchen   \n1057                     Data Engineer           Back Market       Bordeaux   \n1064     Data Engineer (Platform team)                Veepee          Paris   \n1065            Data Engineer (Remote)                Stuart              N   \n1069   Data engineer  business centric                Heetch          Paris   \n\n           type                                           industry  \\\n0     Full Time                     Vehicles & Autonomous Mobility   \n1     Full Time                     Vehicles & Autonomous Mobility   \n2     Full Time                                      Entertainment   \n3     Full Time                                      Entertainment   \n4     Full Time                                      Entertainment   \n...         ...                                                ...   \n1050        CDI         AdTech / MarTech, E-commerce, IT / Digital   \n1057        CDI  Collaborative Economy, E-commerce, Environment...   \n1064        CDI                                         E-commerce   \n1065        CDI                   Collaborative Economy, Logistics   \n1069        CDI                              Mobile Apps, Mobility   \n\n                            remote created_at  \\\n0                          Inconnu 2021-12-27   \n1                          Inconnu 2021-12-27   \n2                          Inconnu 2021-12-27   \n3                          Inconnu 2021-12-27   \n4                          Inconnu 2021-12-27   \n...                            ...        ...   \n1050                       Inconnu 2022-01-25   \n1057                       Inconnu 2022-01-25   \n1064  TÃ©lÃ©travail partiel possible 2022-01-25   \n1065    TÃ©lÃ©travail total possible 2022-01-25   \n1069                       Inconnu 2022-01-25   \n\n                                                   text  \\\n0     At Lyft, our mission is to improve peopleâ€™s li...   \n1     Data Engineer\\nAbout Us\\nWith electric vehicle...   \n2     Delivering the best Spotify experience possibl...   \n3     Delivering the best Spotify experience possibl...   \n4     The Platform team creates the technology that ...   \n...                                                 ...   \n1050  We are the Global Savings Group, the leading E...   \n1057  BackMarket is the number one European (and soo...   \n1064  Avec VEEPEE, le groupe vente-privee ouvre un n...   \n1065  Stuart (DPD Group) is a sustainable ðŸŒ± last-mil...   \n1069  Heetch: the VTC that keeps everyone moving. Ou...   \n\n                                         processed_text lang  length_text  \\\n0     lyft mission improve people life world best tr...   en         2672   \n1     data engineer u electric vehicle ev expected n...   en         3229   \n2     delivering best spotify experience possible ma...   en         4143   \n3     delivering best spotify experience possible ma...   en         5233   \n4     platform team creates technology enables spoti...   en         4186   \n...                                                 ...  ...          ...   \n1050  global saving group leading european commerce ...   en         3190   \n1057  backmarket number one european soon global mar...   en         4204   \n1064  veepee groupe venteprivee ouvre nouveau chapit...   en         5032   \n1065  stuart dpd group sustainable lastmile delivery...   en         4097   \n1069  heetch vtc keep everyone moving mission heetch...   en         5692   \n\n                                                technos  \n0     [S3, Flyte, ETL, Stackdriver, Kafka, Hive, Spa...  \n1     [mlflow, nodejs, airflow, Python, Airflow, Kub...  \n2     [Dataflow, Kubeflow, Pub/Sub, BigQuery, Apache...  \n3                                 [Scala, Python, Java]  \n4     [Scala, Google Cloud Platform, Python, Java, SQL]  \n...                                                 ...  \n1050  [S3, Hadoop, Scala, Flink, Glue, EMR, SQL, Spa...  \n1057  [NoSQL, Kafka, Go, Spark, Participating, Pytho...  \n1064  [Grafana, PostgreSQL, Kafka, Proficiency, Pyth...  \n1065  [S3, Redshift, Hadoop, Flink, Kafka, SparkSQL,...  \n1069  [Morocco, Algeria, airflow, SMS, Python, Looke...  \n\n[523 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>title</th>\n      <th>company</th>\n      <th>location</th>\n      <th>type</th>\n      <th>industry</th>\n      <th>remote</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>processed_text</th>\n      <th>lang</th>\n      <th>length_text</th>\n      <th>technos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://datai.jobs/job/lyft-data-engineer-kyiv...</td>\n      <td>Data Engineer â€“ Kyiv</td>\n      <td>Lyft</td>\n      <td>Kyiv, Ukraine</td>\n      <td>Full Time</td>\n      <td>Vehicles &amp; Autonomous Mobility</td>\n      <td>Inconnu</td>\n      <td>2021-12-27</td>\n      <td>At Lyft, our mission is to improve peopleâ€™s li...</td>\n      <td>lyft mission improve people life world best tr...</td>\n      <td>en</td>\n      <td>2672</td>\n      <td>[S3, Flyte, ETL, Stackdriver, Kafka, Hive, Spa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://datai.jobs/job/chargepoint-data-engine...</td>\n      <td>Data Engineer</td>\n      <td>ChargePoint</td>\n      <td>Amsterdam</td>\n      <td>Full Time</td>\n      <td>Vehicles &amp; Autonomous Mobility</td>\n      <td>Inconnu</td>\n      <td>2021-12-27</td>\n      <td>Data Engineer\\nAbout Us\\nWith electric vehicle...</td>\n      <td>data engineer u electric vehicle ev expected n...</td>\n      <td>en</td>\n      <td>3229</td>\n      <td>[mlflow, nodejs, airflow, Python, Airflow, Kub...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://datai.jobs/job/spotify-data-engineer-e...</td>\n      <td>Data Engineer â€“ Experience</td>\n      <td>Spotify</td>\n      <td>Stockholm</td>\n      <td>Full Time</td>\n      <td>Entertainment</td>\n      <td>Inconnu</td>\n      <td>2021-12-27</td>\n      <td>Delivering the best Spotify experience possibl...</td>\n      <td>delivering best spotify experience possible ma...</td>\n      <td>en</td>\n      <td>4143</td>\n      <td>[Dataflow, Kubeflow, Pub/Sub, BigQuery, Apache...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://datai.jobs/job/spotify-staff-data-engi...</td>\n      <td>Staff Data Engineer â€“ Experience</td>\n      <td>Spotify</td>\n      <td>Stockholm</td>\n      <td>Full Time</td>\n      <td>Entertainment</td>\n      <td>Inconnu</td>\n      <td>2021-12-27</td>\n      <td>Delivering the best Spotify experience possibl...</td>\n      <td>delivering best spotify experience possible ma...</td>\n      <td>en</td>\n      <td>5233</td>\n      <td>[Scala, Python, Java]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://datai.jobs/job/spotify-data-engineer-s...</td>\n      <td>Data Engineer</td>\n      <td>Spotify</td>\n      <td>Stockholm</td>\n      <td>Full Time</td>\n      <td>Entertainment</td>\n      <td>Inconnu</td>\n      <td>2021-12-27</td>\n      <td>The Platform team creates the technology that ...</td>\n      <td>platform team creates technology enables spoti...</td>\n      <td>en</td>\n      <td>4186</td>\n      <td>[Scala, Google Cloud Platform, Python, Java, SQL]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1050</th>\n      <td>https://www.welcometothejungle.com/fr/companie...</td>\n      <td>Data Engineer</td>\n      <td>GLOBAL SAVINGS GROUP</td>\n      <td>MÃ¼nchen</td>\n      <td>CDI</td>\n      <td>AdTech / MarTech, E-commerce, IT / Digital</td>\n      <td>Inconnu</td>\n      <td>2022-01-25</td>\n      <td>We are the Global Savings Group, the leading E...</td>\n      <td>global saving group leading european commerce ...</td>\n      <td>en</td>\n      <td>3190</td>\n      <td>[S3, Hadoop, Scala, Flink, Glue, EMR, SQL, Spa...</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>https://www.welcometothejungle.com/fr/companie...</td>\n      <td>Data Engineer</td>\n      <td>Back Market</td>\n      <td>Bordeaux</td>\n      <td>CDI</td>\n      <td>Collaborative Economy, E-commerce, Environment...</td>\n      <td>Inconnu</td>\n      <td>2022-01-25</td>\n      <td>BackMarket is the number one European (and soo...</td>\n      <td>backmarket number one european soon global mar...</td>\n      <td>en</td>\n      <td>4204</td>\n      <td>[NoSQL, Kafka, Go, Spark, Participating, Pytho...</td>\n    </tr>\n    <tr>\n      <th>1064</th>\n      <td>https://www.welcometothejungle.com/fr/companie...</td>\n      <td>Data Engineer (Platform team)</td>\n      <td>Veepee</td>\n      <td>Paris</td>\n      <td>CDI</td>\n      <td>E-commerce</td>\n      <td>TÃ©lÃ©travail partiel possible</td>\n      <td>2022-01-25</td>\n      <td>Avec VEEPEE, le groupe vente-privee ouvre un n...</td>\n      <td>veepee groupe venteprivee ouvre nouveau chapit...</td>\n      <td>en</td>\n      <td>5032</td>\n      <td>[Grafana, PostgreSQL, Kafka, Proficiency, Pyth...</td>\n    </tr>\n    <tr>\n      <th>1065</th>\n      <td>https://www.welcometothejungle.com/fr/companie...</td>\n      <td>Data Engineer (Remote)</td>\n      <td>Stuart</td>\n      <td>N</td>\n      <td>CDI</td>\n      <td>Collaborative Economy, Logistics</td>\n      <td>TÃ©lÃ©travail total possible</td>\n      <td>2022-01-25</td>\n      <td>Stuart (DPD Group) is a sustainable ðŸŒ± last-mil...</td>\n      <td>stuart dpd group sustainable lastmile delivery...</td>\n      <td>en</td>\n      <td>4097</td>\n      <td>[S3, Redshift, Hadoop, Flink, Kafka, SparkSQL,...</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>https://www.welcometothejungle.com/fr/companie...</td>\n      <td>Data engineer  business centric</td>\n      <td>Heetch</td>\n      <td>Paris</td>\n      <td>CDI</td>\n      <td>Mobile Apps, Mobility</td>\n      <td>Inconnu</td>\n      <td>2022-01-25</td>\n      <td>Heetch: the VTC that keeps everyone moving. Ou...</td>\n      <td>heetch vtc keep everyone moving mission heetch...</td>\n      <td>en</td>\n      <td>5692</td>\n      <td>[Morocco, Algeria, airflow, SMS, Python, Looke...</td>\n    </tr>\n  </tbody>\n</table>\n<p>523 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_jobs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [],
   "source": [
    "# // TODO Add other NER entities to avoid 'Morocco', 'Algeria'... to be labeled as technos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exporting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "outputs": [],
   "source": [
    "english_jobs.to_csv('english_jobs_ner.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}